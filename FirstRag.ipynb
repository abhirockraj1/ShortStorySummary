{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5777da63-3d70-4f4d-ab5f-f66e4d651570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97dba6ff-c1e8-4951-8c6f-13b545ed5186",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load TXT files separately with metadata\n",
    "def load_txt_files_separately(directory_or_file):\n",
    "    documents = []\n",
    "    if os.path.isfile(directory_or_file) and directory_or_file.endswith(\".txt\"):\n",
    "        with open(directory_or_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            documents.append({\"text\": text, \"metadata\": {\"source\": directory_or_file}})\n",
    "    elif os.path.isdir(directory_or_file):\n",
    "        for filename in os.listdir(directory_or_file):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                filepath = os.path.join(directory_or_file, filename)\n",
    "                with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                    text = f.read()\n",
    "                    documents.append({\"text\": text, \"metadata\": {\"source\": filename}})\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0c5494f-dfc9-41ec-ae60-8b0ff5b764c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "txt_documents = load_txt_files_separately(\"D:/RagStorySummary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "10fae2f7-7328-40d6-bc0b-3a65d52613cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 689, which is longer than the specified 500\n",
      "Created a chunk of size 990, which is longer than the specified 500\n",
      "Created a chunk of size 758, which is longer than the specified 500\n",
      "Created a chunk of size 762, which is longer than the specified 500\n",
      "Created a chunk of size 1246, which is longer than the specified 500\n",
      "Created a chunk of size 717, which is longer than the specified 500\n",
      "Created a chunk of size 635, which is longer than the specified 500\n",
      "Created a chunk of size 574, which is longer than the specified 500\n",
      "Created a chunk of size 649, which is longer than the specified 500\n",
      "Created a chunk of size 756, which is longer than the specified 500\n",
      "Created a chunk of size 749, which is longer than the specified 500\n",
      "Created a chunk of size 631, which is longer than the specified 500\n",
      "Created a chunk of size 712, which is longer than the specified 500\n",
      "Created a chunk of size 560, which is longer than the specified 500\n",
      "Created a chunk of size 541, which is longer than the specified 500\n",
      "Created a chunk of size 565, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    " # Chunk the text with metadata\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunked_docs = []\n",
    "for doc in txt_documents:\n",
    "    chunks = splitter.split_text(doc[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        chunked_docs.append({\"text\": chunk, \"metadata\": doc[\"metadata\"]})\n",
    "\n",
    "texts = [doc[\"text\"] for doc in chunked_docs]\n",
    "metadatas = [doc[\"metadata\"] for doc in chunked_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "738b17be-731d-4d3a-8acb-d4e4275baf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store in FAISS with metadata\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_texts(texts, embeddings, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f62b4279-eca8-40b7-9164-49fe89d3a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "    api_key: str\n",
    "    model_name: str = \"mistralai/mixtral-8x7b-instruct\"\n",
    "    temperature: float = 0\n",
    "\n",
    "    def __init__(self, api_key: str, model_name: str = \"mistralai/mixtral-8x7b-instruct\", temperature: float = 0):\n",
    "        super().__init__(api_key=api_key, model_name=model_name, temperature=temperature)\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    # Your custom function to call the actual LLM (OpenAI API)\n",
    "    def call_openai(self, prompt: str) -> str:\n",
    "        url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "            # \"temperature\": self.temperature\n",
    "            # \"max_tokens\": 500  # Adjust as needed\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            return f\"Error calling OpenAI: {str(e)}\"\n",
    "     \n",
    "    # Required method for LangChain LLM interface\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        # Call your custom function here\n",
    "        result = self.call_openai(prompt)\n",
    "        if stop:\n",
    "            for s in stop:\n",
    "                result = result.split(s)[0]\n",
    "        return result\n",
    "\n",
    "    # Required property for LangChain\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom_openai\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb157ac5-43de-4adc-afd4-2d5fb8dbc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenRouter\n",
    "OPENAI_API_KEY = \"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\"  # Replace with your OpenAI key\n",
    "llm = CustomLLM(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "900c9d0c-47d4-48d2-8853-195842ee7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom prompt\n",
    "prompt_template = \"\"\"Question: {question}\n",
    "Context: {context}\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"question\", \"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fb430c9-81db-4b7e-ae33-03ad258c8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True  # Return source files for reference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "816071c4-bfdc-4eea-90c3-379b5da7a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The short story is about a man who comes to Chicago to reunite with his wife after twenty years. She is there to perform a \"magic\" show for a higher-up at the state university, suggesting that she has a career in a field related to math and science. The man feels like he has lost something, possibly a sense of wonder or optimism, as he observes the world around him. A woman from the university meets him and takes him to see his wife. The weather is dreary, reflecting the man's mood. The story seems to be about the intersection of math, science, and wonder, as well as the reunion of the long-separated couple.\n",
      "Sources: [\"The Hunter's Wife.txt\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you please summarize the short story based on math and science?\"\n",
    "response = rag_chain({\"query\": query})\n",
    "print(\"Answer:\", response[\"result\"])\n",
    "print(\"Sources:\", [doc.metadata[\"source\"] for doc in response[\"source_documents\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d3e5d-5fdb-4c01-a20d-d95f47a366b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
